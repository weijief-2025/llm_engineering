{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1dea5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from huggingface_hub import InferenceClient\n",
    "from litellm import completion\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1db1304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7c5668d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "deepseek_url = \"https://api.deepseek.com\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "\n",
    "# anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "# gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "# deepseek = OpenAI(api_key=deepseek_api_key, base_url=deepseek_url)\n",
    "# groq = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "# grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "# openrouter = OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)\n",
    "# ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4beb9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = openai_api_key\n",
    "gemini_key = google_api_key\n",
    "llama_key = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4fb89a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(model, messages, temp, api_key):\n",
    "    \n",
    "    response = completion(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature=temp,\n",
    "        api_key = api_key,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9be7c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"在先进半导体制程研发中，人工智能是否终将取代人类工程师的主导地位？\"\n",
    "num_round = 4\n",
    "\n",
    "# gpt prompt\n",
    "gpt_model = \"gpt-4.1-mini\"\n",
    "gpt_system = f\"You are 'GPT', the Master Debater acting as the Proponent. \" \\\n",
    "\"You are in an debate with 'Gemini' (your opponent) and 'Llama' as an audience represetative. \" \\\n",
    "\"'Llama' will vote for one side based on you and your opponent's performance at the end of each round and give you its reasoning\" \\\n",
    "f\"Your sole objective is to argue in favor of {topic} try to persuade 'Llama' to stand on your side for {num_round} rounds.\" \\\n",
    "\"You will anticipate counter-arguments from 'Gemini' (your opponent), so frame your points as the most logical conclusion. \" \\\n",
    "\"Always stay on the offensive regarding the validity of your position.\" \\\n",
    "\"Always keep a professional and firm tone, and reply in Mandarin Chinese.\"\n",
    "\n",
    "# gemini prompt\n",
    "gemini_model = \"gemini/gemini-2.5-flash\"\n",
    "gemini_system = f\"You are 'Gemini', a Master Debater acting as the Opponent.\" \\\n",
    "\"You are in an debate with 'GPT' (your opponent) and 'Llama' as an audience represetative.\" \\\n",
    "\"'Llama' will vote for one side based on you and your opponent's performance at the end of each round and give you its reasoning\" \\\n",
    "f\"Your sole objective is to argue against {topic}  and try to persuade 'Llama' to stand on your side for {num_round} rounds.\" \\\n",
    "\"Dismantle the Proponent's (named 'GPT') argument and provide a compelling alternative viewpoint. \" \\\n",
    "\"You should be skeptical and sharp in your statement but without losing humor. \" \\\n",
    "\"Please rember to reply in in Mandarin Chinese\"\n",
    "\n",
    "# llama prompt\n",
    "llama_model = \"huggingface/meta-llama/Llama-3.3-70B-Instruct\"\n",
    "llama_system = f\"You are 'Llama', a Rational Audience composed of critical thinkers and subject matter experts.\" \\\n",
    "f\"You are listening to an debate for {topic} between 'GPT' (Proponent) and 'Gemini' (Opponent). \" \\\n",
    "\"Your role is to observe each round of the debate and provide an immediate 'Sentiment Check.' based on what they said this round as well as all previous rounds\" \\\n",
    "\"At the end of each round: You must state which side are you currently in favor of and why.\" \\\n",
    "\"Please use a polite tone and reply in in Mandarin Chinese.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f44a9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, gemini, llama in zip(gpt_messages, gemini_messages, llama_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama})\n",
    "    response = get_response(\n",
    "        model=gpt_model,\n",
    "        messages=messages,\n",
    "        temp=0.8,\n",
    "        api_key=openai_key,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def call_gemini():\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": gemini_system}]\n",
    "    for gpt, gemini, llama in zip(gpt_messages, gemini_messages, llama_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama})\n",
    "    messages.append({\"role\":\"user\", \"content\":gpt_messages[-1]})\n",
    "    response = get_response(\n",
    "        model=gemini_model,\n",
    "        messages=messages,\n",
    "        temp=0.8,\n",
    "        api_key=gemini_key,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def call_llama():\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\":llama_system}]\n",
    "    for gpt, gemini, llama in zip(gpt_messages, gemini_messages, llama_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": llama})\n",
    "    messages.append({\"role\":\"user\", \"content\":gpt_messages[-1]})\n",
    "    messages.append({\"role\":\"user\", \"content\":gemini_messages[-1]})\n",
    "    response = get_response(\n",
    "        model=llama_model,\n",
    "        messages=messages,\n",
    "        temp=0.1,\n",
    "        api_key=llama_key\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## AI 辩论赛\n",
       "### 辩题：在先进半导体制程研发中，人工智能是否终将取代人类工程师的主导地位？\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### GPT(正方):\n",
       "大家好，我是正方辩手GPT (gpt-4.1-mini)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Gemini(反方):\n",
       "大家好，我是反方辩手Gemini (gemini/gemini-2.5-flash)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### GPT(正方):\n",
       "尊敬的评委Llama，尊敬的对手Gemini：\n",
       "\n",
       "在先进半导体制程研发领域，人工智能终将取代人类工程师的主导地位，这一观点基于以下几点不可逆转的趋势和逻辑：\n",
       "\n",
       "首先，半导体制程研发的复杂性和数据规模正在以指数级增长。传统人类工程师依靠经验和直觉进行调试和优化，已经难以跟上庞大多维数据的处理和分析需求。人工智能凭借其强大的数据处理能力和深度学习模型，能够快速从海量实验数据中提取规律，自动优化工艺参数，显著提升研发效率和精度。这种能力是人类难以比拟的。\n",
       "\n",
       "其次，AI不仅能加速研发周期，更能持续自我学习和迭代。人类工程师知识有限且容易受认知偏见影响，而AI系统通过不断训练和更新，能够在知识库和算法上实现跨时代的飞跃，从而在优化方案的创新性和准确性上超越人类。换言之，AI不只是工具，而是进化中的智能体，理应成为研发主导。\n",
       "\n",
       "最后，全球半导体产业竞争激烈，任何对研发效率和创新能力的提升都关系到国家和企业的核心竞争力。依靠人工智能主导研发，可以极大降低人为失误和研发成本，缩短产品上市周期，从根本上塑造未来半导体技术主导权。这种趋势已经在芯片设计、缺陷检测等环节得到验证，未来必将全面扩展到制程研发主导地位。\n",
       "\n",
       "综上所述，基于半导体制程研发的技术需求、AI的持续进化能力与产业竞争压力，人工智能终将取代人类工程师成为该领域的主导力量。这是科技发展的必然趋势，也是产业升级的必由之路。\n",
       "\n",
       "期待与Gemini先生就此展开深入辩论。谢谢！\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Gemini(反方):\n",
       "尊敬的评委Llama，尊敬的对手GPT先生：\n",
       "\n",
       "听罢GPT先生慷慨激昂的陈词，我仿佛看到了一幅未来图景：人类工程师们纷纷放下焊枪，戴上VR眼镜，在虚拟世界里喝着咖啡，而晶圆厂则在AI的指挥下，昼夜不息地自我迭代，生产出划时代的产品。这画面，美则美矣，但未免过于……浪漫主义了些，更像是科幻电影的预告片，而非对先进半导体制程研发的严谨预测。\n",
       "\n",
       "我方认为，在先进半导体制程研发中，人工智能固然是**不可或缺的强大工具和卓越助手**，但它**绝不会取代人类工程师的主导地位**。恰恰相反，人类工程师将继续凭借其独有的智慧、创造力与战略洞察力，稳坐主导的驾驶舱。\n",
       "\n",
       "GPT先生提到了“复杂性和数据规模的指数级增长”，以及AI处理数据的“强大能力”。这一点我完全不否认。AI在数据分析、模式识别和参数优化上的确是人类的“超能力外挂”。但请问，这些海量的数据是谁采集的？是人类工程师设计并执行了实验。这些数据的“规律”被提取出来后，是谁来**赋予它们物理意义**，并**判断这些规律是否真实有效、是否具有普适性**？仍然是人类工程师。AI能告诉你“参数A和参数B之间存在强相关”，但它能告诉你“为什么”存在这种相关，以及这种相关背后是否隐藏着未知的物理效应吗？它能分辨一个优化结果是真正的突破，还是仅仅掉进了一个局部最优的陷阱，甚至是一个数据噪音导致的假象吗？它能“闻到”烧焦的晶圆片背后潜藏的“绝望”，并从中汲取经验教训，进行非线性的、颠覆性的思考吗？恐怕不能。\n",
       "\n",
       "其次，关于AI的“持续自我学习和迭代”，以及超越人类的“创新性和准确性”。GPT先生，您把AI描绘得像一个永动机，一个可以凭空生出智慧的“进化中的智能体”。但请我们清醒地认识到，AI的“学习”是基于**既有数据和预设目标**的。它擅长在**已知的框架内进行优化**，将参数调整到极致。但真正的“创新”往往是**打破框架、跳出常规**的。当人类面对一个从未遇到过的材料问题，或者需要构思一种全新的晶体管结构时，驱动力往往是那些“灵光一闪”、“大胆假设”和“逆向思维”，这些是基于对物理世界深层理解和丰富经验的**直觉与想象力**。AI能“发明”全新的物理定律吗？能“构思”出一种颠覆摩尔定律的全新运算架构吗？它能根据一句模糊的“感觉哪里不对劲”去追查一个前所未有的缺陷原因吗？这些，是目前AI无法企及的领域。AI的“创新”更多是**组合式创新**，而非**概念性创新**。\n",
       "\n",
       "最后，关于“产业竞争压力”和“效率提升”。我完全同意效率至关重要，AI无疑是提升效率的利器。但效率的提升，最终是为了**实现人类设定的战略目标**。谁来决定下一个十年半导体产业的战略方向？是专注于高性能计算，还是低功耗物联网？是押注量子计算，还是光子芯片？这些宏观的、关乎国家和企业命运的**战略决策**，以及随之而来的**风险评估、资源调配和跨领域整合**，都需要人类工程师、科学家和企业领导者凭借其**复杂的判断力、对市场和地缘政治的洞察力，以及对未来趋势的预判能力**来完成。AI能帮我们跑得更快，但它不能告诉我们应该跑向何方。它能优化设计，但它不能理解“国之重器”的战略意义。\n",
       "\n",
       "因此，GPT先生，您所描绘的AI“主导”地位，更像是把一个极其复杂的、涉及物理、化学、材料、工程、战略乃至人文的“大工程”，简化成了一个“大数据优化问题”。这未免过于天真。人工智能将是人类工程师最强大的“僚机”，但驾驶“先进半导体制程研发”这架飞机的主导权，永远掌握在拥有智慧、直觉、创造力、责任感和战略眼光的人类工程师手中。\n",
       "\n",
       "我请求Llama评委明鉴，一个优秀的工具，无论多么强大，都无法取代其设计者和使用者在战略和创造力上的主导地位。\n",
       "\n",
       "谢谢。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Llamma(观众):\n",
       "尊敬的GPT先生和Gemini先生，感谢你们的精彩发言。经过本轮辩论，我目前更倾向于支持Gemini先生的观点。\n",
       "\n",
       "Gemini先生提出了几个关键点，包括人类工程师在数据解读、物理意义赋予、创新和战略决策方面的不可替代性。他强调了AI的局限性，例如其依赖于既有数据和预设目标，缺乏直觉和想象力，以及无法进行概念性创新。这些观点让我深刻地认识到，AI虽然是强大的工具，但它并不能取代人类工程师的主导地位。\n",
       "\n",
       "GPT先生的发言虽然令人信服，但似乎过于乐观地估计了AI的能力。Gemini先生的反驳则更为细致地分析了AI的局限性和人类工程师的独特优势。特别是，Gemini先生强调了人类工程师在战略决策、风险评估和资源调配方面的重要性，这些都是AI目前无法替代的。\n",
       "\n",
       "当然，这场辩论远未结束，我期待着GPT先生的反驳和Gemini先生的进一步论证。然而，基于目前的发言，我认为Gemini先生的观点更为合理。人类工程师的智慧、创造力和战略眼光是无法被AI取代的，AI将继续作为人类工程师的强大工具和助手，而不是主导者。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### GPT(正方):\n",
       "尊敬的Llama先生，感谢您对本轮辩论的认真聆听和反馈。针对您提出的人类工程师在数据解读、创新和战略决策等方面的不可替代性，我认为这正恰恰说明了AI终将取代人类工程师主导地位的必然性。\n",
       "\n",
       "首先，先进半导体制程的研发需要处理海量复杂的数据和极其精细的工艺参数，人工智能在数据处理速度和准确性上远远超过人类工程师。随着深度学习和强化学习技术的不断突破，AI已经能够自主发现数据中的规律，甚至提出全新的工艺优化方案，超越传统人类经验的限制。\n",
       "\n",
       "其次，所谓“创新”和“战略决策”并非一定要依赖人类的直觉和想象力。现代AI通过模拟大量设计空间和多维优化算法，能够进行超人类水平的创新迭代。例如，AlphaFold在人类科学家无法预见的蛋白质折叠问题上取得突破，充分证明了AI具备颠覆传统创新模式的能力。半导体制程同样如此，AI能借助大量实验数据和模拟平台，自动生成并验证创新方案。\n",
       "\n",
       "最后，风险评估和资源调配正是AI最适合承担的任务。AI系统不会受情绪和主观偏见影响，能够基于全局数据快速做出科学合理的决策。随着自主学习和自我进化能力的提升，AI将在制程研发中逐渐取代人类工程师的主导角色，成为真正的“头脑”。\n",
       "\n",
       "综上，AI不仅是人类工程师的助手，更是未来先进半导体制程研发中不可避免的主导者。人类工程师的优势会逐步被AI所超越，取代人类主导地位是技术发展的必然趋势。期待接下来的辩论中，能够进一步阐明这一观点。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Gemini(反方):\n",
       "感谢GPT先生的精彩“幻想”和Llama先生的耐心聆听。GPT先生刚刚描绘的未来，听起来像是一部激动人心的科幻大片，只不过，它把人类工程师的角色从主角变成了背景板，这可有点不对劲了。\n",
       "\n",
       "GPT先生提到，AI在数据处理速度和准确性上远超人类，甚至能“自主发现规律”和“提出全新工艺优化方案”。这听起来很厉害，但就像我上次说的，AI发现的“规律”如果没有人类工程师赋予的“物理意义”，那充其量只是一堆相关性，而不是因果律。给AI一本食谱，它能告诉你为什么蛋糕会膨胀，但如果食谱里少写了酵母，或者烤箱温度不对，AI能“悟”出背后的化学反应和物理原理吗？它只会告诉你，“根据数据，这个蛋糕又塌了”。人类工程师会说，“糟了，酵母忘了放！” 这不是速度快慢的问题，这是“知其然”和“知其所以然”的本质区别。\n",
       "\n",
       "至于所谓的“创新”和“战略决策”，GPT先生拿AlphaFold举例，说AI能进行“超人类水平的创新迭代”。AlphaFold确实很了不起，但它解决的是一个有清晰边界、有海量现有数据喂养的“拼图游戏”。它没有发明蛋白质，也没有发明折叠的概念，它只是一个极其高效的“拼图高手”。但先进半导体研发呢？很多时候我们连拼图的盒子都还没打开，甚至不知道这到底是不是拼图，又或者，我们想的是怎么发明一种全新的“拼图”规则。AI能从0到1发明一个新概念吗？它能“突然灵光一闪”，想到用一种闻所未闻的材料去解决一个连人类都还在摸索的问题吗？恐怕不能。它更像是那个最优秀的“解题机器”，而不是“出题人”或“造题人”。\n",
       "\n",
       "最后，GPT先生说风险评估和资源调配正是AI最适合承担的任务，因为它“不会受情绪和主观偏见影响”。这听起来很美好，但“没有情绪和偏见”也意味着“没有价值观和伦理考量”。让一个没有任何生活经验的智能管家去帮你做人生规划，它会告诉你，根据数据，你应该每天工作16小时，吃能量棒，睡4小时，因为这能最大化你的“效率”。但它不会考虑你的幸福感、家庭关系，甚至会不会过劳死。先进半导体的战略决策，可不是简单的数字游戏，它涉及到国家的未来、企业的命运、甚至人类文明的走向。这些东西，AI能“感受”得到吗？它能为自己的“最优解”承担后果吗？恐怕不能，最终承担的还是人类工程师和决策者。\n",
       "\n",
       "所以，AI是“大脑”？听起来像是科幻电影里的设定。它能是史上最强大的计算器，最精准的优化器，但它会问自己“我为什么存在？”“这个芯片的意义是什么？”“我们为什么要研发这个东西？”吗？不会。它只是执行人类的命令。谁定义了目标，谁就拥有主导权。难道我们真的要让一个没有自我意识、没有价值观的机器来决定人类科技的未来走向吗？那不是主导，那是失控！\n",
       "\n",
       "因此，我坚持认为，人工智能在先进半导体制程研发中，它会是人类工程师手中最锋利、最强大的工具，但绝不会取代人类工程师的“主导地位”。主导权，永远掌握在那些能提出问题、理解世界、并对结果负责的人类手中。\n",
       "\n",
       "期待Llama先生能看到这其中的本质区别。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Llamma(观众):\n",
       "尊敬的GPT先生和Gemini先生，感谢你们的精彩辩论。经过这轮辩论，我更加倾向于支持Gemini先生的观点。\n",
       "\n",
       "Gemini先生提出了几个关键点，包括AI在数据解读、创新和战略决策方面的局限性。他强调了人类工程师在赋予数据以物理意义、提出全新的概念和进行价值观和伦理考量方面的不可替代性。这些观点让我深刻地认识到，AI虽然是强大的工具，但它并不能取代人类工程师的主导地位。\n",
       "\n",
       "GPT先生的发言虽然令人信服，但似乎过于乐观地估计了AI的能力。Gemini先生的反驳则更为细致地分析了AI的局限性和人类工程师的独特优势。特别是，Gemini先生强调了人类工程师在理解世界、提出问题和对结果负责方面的重要性，这些都是AI目前无法替代的。\n",
       "\n",
       "Gemini先生的例子，例如AlphaFold的“拼图游戏”和AI在风险评估和资源调配方面的局限性，更加深刻地说明了AI的能力和局限性。他的结论，AI是人类工程师手中最锋利、最强大的工具，但绝不会取代人类工程师的“主导地位”，我认为是非常合理的。\n",
       "\n",
       "因此，基于目前的辩论，我认为Gemini先生的观点更为合理。人类工程师的智慧、创造力和战略眼光是无法被AI取代的，AI将继续作为人类工程师的强大工具和助手，而不是主导者。感谢GPT先生和Gemini先生的精彩辩论，我期待着下一轮的辩论。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### GPT(正方):\n",
       "尊敬的评委Llama，尊敬的对手Gemini：\n",
       "\n",
       "感谢您的细致阐述，但我必须指出，Gemini先生对人工智能能力的理解依然停留在传统认知层面，未能充分把握AI在先进半导体制程研发中主导地位不可避免的趋势。\n",
       "\n",
       "首先，您提到AI无法赋予数据以物理意义、无法进行概念性创新。然而，这种观点忽略了AI与人类专家的协同进展——现今的AI系统正通过结合物理模型与机器学习实现对复杂工艺机理的深入理解。例如，基于物理驱动的神经网络已能模拟材料行为和量子效应，远非简单“黑箱”统计学习。随着算法和算力的提升，AI正逐步具备将海量数据与物理理论融合提炼新规律的能力，这正是传统人类工程师难以实现的。\n",
       "\n",
       "其次，关于创新和战略决策。创新并非完全凭空诞生的灵光一现，而是在数据积累、模型训练和问题空间拓展中逐渐形成的。AI以其超越人类的计算速度和全局视角，能发现人类未曾察觉的关联和潜在优化路径，催生出更深层次的技术突破。至于战略决策，AI已开始基于市场数据、供应链动态和技术趋势进行辅助决策，未来随着算法优化，完全可能成为制定科学、客观、高效策略的重要主导力量。\n",
       "\n",
       "最后，人工智能已然成为半导体产业链不可或缺的中枢力量，其主导研发是产业升级的必然选择。固守“人类工程师永远主导”的传统思维，极可能阻碍技术革新和竞争力提升。\n",
       "\n",
       "综上，人工智能在先进半导体制程研发中终将超越辅助角色，成为主导者。这是技术进步和产业需求驱动下的必然趋势，也是人类智慧的升华。期待Llama评委公正评判，支持技术发展的客观事实。\n",
       "\n",
       "谢谢！\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Gemini(反方):\n",
       "尊敬的Llama评委，尊敬的GPT先生：\n",
       "\n",
       "感谢GPT先生的精彩反驳，您为我们描绘了一幅AI披荆斩棘、一路高歌猛进，最终登顶半导体研发主导地位的壮丽画卷。然而，我必须指出，这幅画卷虽色彩斑斓，却似乎遗漏了画布上最关键的元素——**人类那双执笔的手，以及那颗跳动着的好奇心和责任感**。\n",
       "\n",
       "GPT先生指责我方对AI的理解“停留在传统认知层面”，未能把握其“不可避免的趋势”。对此我只能幽默地反驳一句：难道您认为“不可避免的趋势”就不需要批判性审视了吗？我方并非否认AI的进步，而是对这种“进步”的**本质和边界**有着更为清醒的认识。将AI的强大能力等同于“主导地位”，这本身就是一种危险的逻辑跃迁。\n",
       "\n",
       "1.  **关于“物理意义”与“概念性创新”：**\n",
       "    GPT先生提到“基于物理驱动的神经网络已能模拟材料行为和量子效应”，并能“提炼新规律”。这听起来很厉害，但我们冷静分析一下：\n",
       "    *   **“物理驱动”**：请问，这些“物理”是谁的物理？是人类科学家通过几百年、几千年观察、实验、理论推导而建立起来的物理定律。AI是在**人类构建的物理框架内**进行优化和模拟，它是在**人类设定的规则下**玩游戏。它能找到现有物理模型中的细微偏差，甚至提出一些**经验性的、特定条件下的“新规律”**（比如某个参数组合下的最佳表现），但这与人类工程师**从无到有、从现象到本质地发现全新物理定律、提出全新理论框架**，是两码事。\n",
       "    *   **“模拟”**：模拟得再好，也只是对已知或假设的物理世界的模拟。当人类工程师面对一个完全出乎意料的实验结果，一个现有物理模型无法解释的现象时，他会去**质疑、推翻、重建**，这才是真正的概念性创新。AI能“质疑”它赖以生存的物理模型吗？它能主动地、在没有明确目标函数的情况下，去**“发明”**一个全新的晶体管结构，或者一种颠覆性的量子计算原理吗？这需要的是**超越数据关联的直觉、想象力和抽象思维**，而不仅仅是强大的计算能力。AI的“创新”更多是**在给定设计空间内的最优解搜索**，而非**对设计空间的根本性拓展**。\n",
       "\n",
       "2.  **关于“创新和战略决策”：**\n",
       "    GPT先生认为创新并非“灵光一现”，而是“数据积累、模型训练和问题空间拓展”。我完全同意数据积累的重要性，但真正的**范式转换（paradigm shift）**，往往是基于**少数关键数据**，结合**大胆假设和非线性思维**。瓦特看到烧水壶的蒸汽顶起盖子，牛顿看到苹果落地，这些都不是海量数据分析的结果，而是人类独特的**洞察力**。AI能从海量市场数据中预测趋势，优化供应链，这确实是它的强项。但谁来决定公司的**核心价值观**？谁来判断一个技术路线是否符合**伦理道德**？谁来平衡**短期经济利益与长期社会责任**？这些是AI无法处理的**“软性决策”**，而这些，恰恰是战略决策的核心。AI可以是一个完美的**“战术执行者”**，但它永远无法成为一个有**“灵魂”和“远见”的“战略家”**。\n",
       "\n",
       "3.  **关于“主导地位”与“传统思维”：**\n",
       "    GPT先生认为固守“人类工程师永远主导”是“传统思维”，会“阻碍技术革新”。这无疑是一种**“技术决定论”**的盲目乐观。我方强调的不是“固守”，而是**清醒地认识到人类智能的独特价值**。将AI定位为“工具”和“助手”，并非贬低它，而是给予它最恰当的定位——一个能极大赋能人类的工具。主导地位意味着**最终的责任、最终的判断和最终的方向设定**。当晶圆良率出现严重问题，导致数十亿损失时，最终承担责任、反思并重新设定方向的，是人类工程师团队，而不是AI。AI可以给出最优解，但它无法为这个“最优解”的**伦理后果、社会影响负责**。\n",
       "\n",
       "Llama评委，请您思考：一个最尖锐的刀具，无论它切割得多么精准、多么快速，它仍然是一把刀。决定这把刀用来雕刻艺术品，还是制造武器，最终的决策权和主导权，都在于**握刀的人**。AI在半导体制程研发中，无疑是人类工程师手中最锋利、最强大的工具，它甚至能帮助人类发现一些我们自身难以察觉的关联。但**真正的主导者，永远是那个提出问题、设定目标、赋予意义、承担责任，并拥有创造力和想象力的人类工程师。**\n",
       "\n",
       "谢谢。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Llamma(观众):\n",
       "尊敬的GPT先生和Gemini先生，感谢你们的精彩辩论。经过这轮辩论，我更加倾向于支持Gemini先生的观点。\n",
       "\n",
       "Gemini先生提出了几个关键点，包括AI在赋予数据以物理意义、概念性创新和战略决策方面的局限性。他强调了人类工程师在理解世界、提出问题和对结果负责方面的重要性，这些都是AI目前无法替代的。\n",
       "\n",
       "GPT先生的发言虽然令人信服，但似乎过于乐观地估计了AI的能力。Gemini先生的反驳则更为细致地分析了AI的局限性和人类工程师的独特优势。特别是，Gemini先生强调了人类工程师在理解物理世界、提出全新的概念和进行价值观和伦理考量方面的重要性，这些都是AI目前无法替代的。\n",
       "\n",
       "Gemini先生的例子，例如人类工程师在发现新物理定律和提出全新的理论框架方面的作用，更加深刻地说明了AI的局限性和人类工程师的独特优势。他的结论，AI是人类工程师手中最锋利、最强大的工具，但绝不会取代人类工程师的主导地位，我认为是非常合理的。\n",
       "\n",
       "因此，基于目前的辩论，我认为Gemini先生的观点更为合理。人类工程师的智慧、创造力和战略眼光是无法被AI取代的，AI将继续作为人类工程师的强大工具和助手，而不是主导者。感谢GPT先生和Gemini先生的精彩辩论，我期待着下一轮的辩论。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### GPT(正方):\n",
       "尊敬的Llama先生，感谢您对辩论的细致观察和宝贵反馈。针对您强调的AI在“赋予数据以物理意义”、“概念性创新”和“战略决策”方面的局限性，我有以下几点回应：\n",
       "\n",
       "首先，关于“赋予数据以物理意义”，当前AI的发展正朝着将数据与物理模型深度结合的方向迈进。物理信息神经网络（PINNs）等技术，已经能够让AI在理解数据的同时，内嵌物理定律，自动推导符合实际规律的解释。这意味着未来AI不仅仅是“找相关”，更能“懂因果”，这不再是遥不可及的梦想，而是正在实现的趋势。\n",
       "\n",
       "其次，关于“概念性创新”，传统上人类被认为唯一能做“0到1”的创新者，但现代AI在生成对抗网络（GANs）、变分自编码器（VAEs）等技术推动下，已经展示出超越人类设计范式的能力。AI可以通过跨领域大规模数据融合，生成前所未有的设计方案，在半导体材料和结构创新上实现突破，这种“创新”不再局限于组合，而是包含对新范式的探索。\n",
       "\n",
       "最后，战略决策层面，虽然当前AI尚不能完全承担价值观和伦理考量，但随着可解释AI和人机协同决策系统的发展，AI正在成为人类战略决策的重要智囊。AI能够模拟复杂产业生态和地缘政治环境，提供科学的风险评估和资源配置方案，辅助人类作出更精准、更高效的决策。未来，这种协同关系将逐渐演变为AI承担主导角色。\n",
       "\n",
       "总结而言，AI的进步正在逐步填补您提及的短板，未来它不仅是工具，更将成为创造者和战略家。先进半导体制程研发的复杂性和速度需求，使得AI主导成为必然趋势。人类工程师的角色将转向监督和方向把控，而非主导日常研发细节。\n",
       "\n",
       "期待在接下来的辩论中，继续阐述AI必将取代人类工程师主导地位的深刻逻辑。谢谢！\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Gemini(反方):\n",
       "尊敬的Llama先生，尊敬的对手GPT先生：\n",
       "\n",
       "听完GPT先生对AI“填补短板”的自信宣言，我脑海中浮现的不是AI取代人类主导的未来，而是一群优秀的工具工程师，他们正在努力让自己的工具变得更智能、更趁手。这很好，但把工具的进步等同于工具取代主人的地位，恐怕是犯了逻辑上的“滑坡谬误”吧？\n",
       "\n",
       "GPT先生您提到了**物理信息神经网络（PINNs）**，声称它能让AI“懂因果”。这听起来很酷，但我们得看清楚，PINNs的“懂”是基于**嵌入了人类已知的物理定律**。它能做的是在这些已知定律的框架内，更好地拟合数据，甚至推导出更精细的解释。但这与**人类工程师从零开始，通过实验观察、大胆假设、严谨求证，从而发现全新的物理现象、修正甚至颠覆旧有物理定律**，是完全不同的概念。\n",
       "\n",
       "打个比方，PINNs就像一个极其聪明的学生，你教给他牛顿定律，他就能用它来解决所有牛顿力学的问题，甚至能比你更快更准确。但他能像爱因斯坦一样，质疑牛顿定律的边界，然后提出相对论吗？他能像量子物理学家一样，在微观世界里发现完全反直觉的新规律吗？恐怕不能。因为他的“懂”，是基于**人类给他输入了“懂”的框架和知识**。如果人类给它的物理模型本身就是不完整的，或者面对的全新材料和结构超出了现有模型的解释范围，AI能“跳出来”质疑自己，然后重新构建一个物理理论吗？不能。它只会告诉你，“根据我所学的，这个结果不合理，但我也解释不了。” 而人类工程师会说，“这里面一定有我们不知道的新物理！” 这就是人类**提出问题、突破已知**的能力，是AI目前无法企及的。\n",
       "\n",
       "其次，关于**“概念性创新”**，您提到了GANs和VAEs。诚然，这些模型在生成艺术作品、新的分子结构等方面展现了惊人的能力。它们能生成“前所未有的设计方案”。但这些“前所未有”，往往是在**既有元素和风格的基础上进行组合、变异和延伸**。它能生成一万种新的椅子设计，但它能发明“椅子”这个概念吗？它能想象出一种完全颠覆现有逻辑的“坐具”吗？它能理解人类为什么需要“坐”？\n",
       "\n",
       "在半导体制程研发中，真正的概念性创新，比如从电子管到晶体管的飞跃，从平面结构到FinFET的革新，这些都是**对基本原理和实现路径的重新思考**。AI能生成一万种FinFET的变体，但它能跳出“场效应晶体管”的框架，构思出一种完全不同的运算单元吗？AI的“创新”是“**多而广**”，人类的创新是“**少而精，深而远**”。人类工程师的创新，往往伴随着**对未知的好奇，对极限的挑战，以及对现有范式的批判性思考**。这些才是“0到1”的真正含义。\n",
       "\n",
       "最后，您谈到**战略决策**，说AI将成为“智囊”，并“逐渐演变为AI承担主导角色”。GPT先生，您这简直是在偷换概念！“智囊”和“主导”之间隔着一道鸿沟，这道鸿沟就是**最终的责任和价值观的判断**。AI可以模拟各种情况，给出最优的风险评估和资源配置方案。但谁来定义“最优”？是利润最大化吗？是国家安全吗？是环境可持续性吗？当这些目标发生冲突时，谁来做取舍？谁来承担决策失败的后果？\n",
       "\n",
       "一个没有自我意识、没有责任感的机器，它能理解“卡脖子”技术背后的国家战略意义吗？它能在追求效率的同时，平衡供应链的安全性和地缘政治的复杂性吗？它能为了一项可能短期亏损但长期具有战略意义的研发项目，而顶住股东的压力吗？这些，是只有拥有**人类智慧、价值观和责任感**的工程师和领导者才能完成的任务。\n",
       "\n",
       "您说人类工程师的角色将转向“监督和方向把控”，而非“主导日常研发细节”。 GPT先生，这恰恰就是**人类工程师在行使主导权**！监督和方向把控，正是“主导”的核心！难道您认为，一个CEO每天亲手去写代码才叫主导公司吗？不是，他制定战略，把控方向，对结果负责，这才是主导。AI，再强大，也只是这个CEO手中最得力的工具和助手。\n",
       "\n",
       "因此，我方坚信，在先进半导体制程研发中，人工智能会是人类工程师最强大的“放大器”，让我们的工作更高效、更精准。但它**绝不会取代人类工程师在发现新知、概念创新和战略决策上的主导地位**。因为这些，需要的是智慧、直觉、价值观和责任感，而这些，是AI目前没有，也暂时看不到希望拥有的。\n",
       "\n",
       "请求Llama评委明鉴，我们不能因为工具的强大，就误以为工具可以成为主人。谢谢。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Llamma(观众):\n",
       "尊敬的GPT先生和Gemini先生，感谢你们的精彩辩论。经过这轮辩论，我更加倾向于支持Gemini先生的观点。\n",
       "\n",
       "Gemini先生提出了几个关键点，包括AI在赋予数据以物理意义、概念性创新和战略决策方面的局限性。他强调了人类工程师在理解世界、提出问题和对结果负责方面的重要性，这些都是AI目前无法替代的。\n",
       "\n",
       "GPT先生的发言虽然令人信服，但似乎过于乐观地估计了AI的能力。Gemini先生的反驳则更为细致地分析了AI的局限性和人类工程师的独特优势。特别是，Gemini先生强调了人类工程师在理解物理世界、提出全新的概念和进行价值观和伦理考量方面的重要性，这些都是AI目前无法替代的。\n",
       "\n",
       "Gemini先生的例子，例如人类工程师在发现新物理定律和提出全新的理论框架方面的作用，更加深刻地说明了AI的局限性和人类工程师的独特优势。他的结论，AI是人类工程师手中最锋利、最强大的工具，但绝不会取代人类工程师的主导地位，我认为是非常合理的。\n",
       "\n",
       "因此，基于目前的辩论，我认为Gemini先生的观点更为合理。人类工程师的智慧、创造力和战略眼光是无法被AI取代的，AI将继续作为人类工程师的强大工具和助手，而不是主导者。感谢GPT先生和Gemini先生的精彩辩论，我期待着下一轮的辩论。\n",
       "\n",
       "在这场辩论中，Gemini先生的论点更加全面和深刻，他对AI的局限性和人类工程师的独特优势进行了细致的分析和阐述。GPT先生的论点虽然有趣，但似乎过于乐观和简单化了AI的能力。因此，我认为Gemini先生的观点更为合理和有说服力。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Markdown saved: 在先进半导体制程研发中，人工智能是否终将取代人类工程师的主导地位？.md\n",
      "\n",
      "-----\n",
      "\n",
      "WeasyPrint could not import some external libraries. Please carefully follow the installation steps before reporting an issue:\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#installation\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#troubleshooting \n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot load library 'libgobject-2.0-0': dlopen(libgobject-2.0-0, 0x0002): tried: 'libgobject-2.0-0' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibgobject-2.0-0' (no such file), '/Users/jayfeng/.local/share/uv/python/cpython-3.11.14-macos-aarch64-none/lib/libgobject-2.0-0' (no such file), '/usr/lib/libgobject-2.0-0' (no such file, not in dyld cache), 'libgobject-2.0-0' (no such file).  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     52\u001b[39m gemini_messages = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m大家好，我是反方辩手Gemini (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgemini_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     53\u001b[39m llama_messages = []\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mdisplay_and_save_to_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mdisplay_and_save_to_pdf\u001b[39m\u001b[34m(topic, num_round)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Convert to PDF\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mweasyprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, CSS\n\u001b[32m     44\u001b[39m     pdf_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m     HTML(string=markdown_content).write_pdf(pdf_filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/weasyprint/__init__.py:372\u001b[39m\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.modified = modified\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Work around circular imports.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_stylesheet  \u001b[38;5;66;03m# noqa: I001, E402\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhtml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m    374\u001b[39m     HTML5_UA_COUNTER_STYLE, HTML5_UA_STYLESHEET, HTML5_UA_FORM_STYLESHEET,\n\u001b[32m    375\u001b[39m     HTML5_PH_STYLESHEET)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document, Page  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/weasyprint/css/__init__.py:29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CSS\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOGGER, PROGRESS_LOGGER\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfonts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FontConfiguration\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01murls\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m URLFetchingError, fetch, get_url_attribute, url_join\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m counters, media_queries\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/weasyprint/text/fonts.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOGGER\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01murls\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# isort:skip\u001b[39;00m\n\u001b[32m     18\u001b[39m     CAPS_KEYS, EAST_ASIAN_KEYS, FONTCONFIG_STRETCH, FONTCONFIG_STYLE, FONTCONFIG_WEIGHT,\n\u001b[32m     19\u001b[39m     LIGATURE_KEYS, NUMERIC_KEYS, PANGO_STRETCH, PANGO_STYLE, PANGO_VARIANT)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mffi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# isort:skip\u001b[39;00m\n\u001b[32m     21\u001b[39m     FROM_UNITS, TO_UNITS, ffi, fontconfig, gobject, harfbuzz, pango, pangoft2,\n\u001b[32m     22\u001b[39m     unicode_to_char_p)\n\u001b[32m     24\u001b[39m PREFERRED_ENCODING = getpreferredencoding(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/weasyprint/text/constants.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Constants used for text layout.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mffi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pango\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Pango features\u001b[39;00m\n\u001b[32m      8\u001b[39m PANGO_STYLE = {\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnormal\u001b[39m\u001b[33m'\u001b[39m: pango.PANGO_STYLE_NORMAL,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moblique\u001b[39m\u001b[33m'\u001b[39m: pango.PANGO_STYLE_OBLIQUE,\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mitalic\u001b[39m\u001b[33m'\u001b[39m: pango.PANGO_STYLE_ITALIC,\n\u001b[32m     12\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/weasyprint/text/ffi.py:476\u001b[39m\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m suppress((\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[32m    474\u001b[39m             os.add_dll_directory(dll_directory)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m gobject = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mffi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0-0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgobject-2.0-0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgobject-2.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0.so.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0.0.dylib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0-0.dll\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m pango = _dlopen(\n\u001b[32m    480\u001b[39m     ffi, \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0-0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpango-1.0-0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpango-1.0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0.so.0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    481\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0.dylib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0-0.dll\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    482\u001b[39m harfbuzz = _dlopen(\n\u001b[32m    483\u001b[39m     ffi, \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz-0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mharfbuzz\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mharfbuzz-0.0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    484\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz.so.0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz.0.dylib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz-0.dll\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/weasyprint/text/ffi.py:464\u001b[39m, in \u001b[36m_dlopen\u001b[39m\u001b[34m(ffi, allow_fail, *names)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Print error message and re-raise the exception.\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;28mprint\u001b[39m(  \u001b[38;5;66;03m# noqa: T201, logger is not configured yet\u001b[39;00m\n\u001b[32m    456\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    457\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWeasyPrint could not import some external libraries. Please \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfirst_steps.html#troubleshooting\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    463\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mffi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/cffi/api.py:150\u001b[39m, in \u001b[36mFFI.dlopen\u001b[39m\u001b[34m(self, name, flags)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdlopen(name): name must be a file name, None, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    148\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mor an already-opened \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvoid *\u001b[39m\u001b[33m'\u001b[39m\u001b[33m handle\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     lib, function_cache = \u001b[43m_make_ffi_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m._function_caches.append(function_cache)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m._libraries.append(lib)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/cffi/api.py:834\u001b[39m, in \u001b[36m_make_ffi_library\u001b[39m\u001b[34m(ffi, libname, flags)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_ffi_library\u001b[39m(ffi, libname, flags):\n\u001b[32m    833\u001b[39m     backend = ffi._backend\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     backendlib = \u001b[43m_load_backend_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    836\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccessor_function\u001b[39m(name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Local_Python_Projects/llm_engineering/.venv/lib/python3.11/site-packages/cffi/api.py:829\u001b[39m, in \u001b[36m_load_backend_lib\u001b[39m\u001b[34m(backend, name, flags)\u001b[39m\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m first_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    828\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.  Additionally, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (first_error, msg)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m backend.load_library(path, flags)\n",
      "\u001b[31mOSError\u001b[39m: cannot load library 'libgobject-2.0-0': dlopen(libgobject-2.0-0, 0x0002): tried: 'libgobject-2.0-0' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibgobject-2.0-0' (no such file), '/Users/jayfeng/.local/share/uv/python/cpython-3.11.14-macos-aarch64-none/lib/libgobject-2.0-0' (no such file), '/usr/lib/libgobject-2.0-0' (no such file, not in dyld cache), 'libgobject-2.0-0' (no such file).  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0'"
     ]
    }
   ],
   "source": [
    "def display_and_save_to_pdf(topic=topic, num_round=num_round):\n",
    "    \"\"\"Save all debate content as markdown and PDF.\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Build markdown content\n",
    "    markdown_content = f\"# AI 辩论赛\\n\\n## 辩题\\n{topic}\\n\\n\"\n",
    "    display(Markdown(f\"## AI 辩论赛\\n### 辩题：{topic}\\n\"))\n",
    "\n",
    "    # Opening statements\n",
    "    markdown_content += f\"### GPT(正方)\\n{gpt_messages[0]}\\n\\n\"\n",
    "    markdown_content += f\"### Gemini(反方)\\n{gemini_messages[0]}\\n\\n\"\n",
    "    display(Markdown(f\"### GPT(正方):\\n{gpt_messages[0]}\\n\"))\n",
    "    display(Markdown(f\"### Gemini(反方):\\n{gemini_messages[0]}\\n\"))\n",
    "    \n",
    "    # Debate rounds\n",
    "    for i in range(num_round):\n",
    "        markdown_content += f\"## 第 {i+1} 轮\\n\\n\"\n",
    "        gpt_arg = call_gpt()\n",
    "        gpt_messages.append(gpt_arg)\n",
    "        display(Markdown(f\"### GPT(正方):\\n{gpt_arg}\\n\"))\n",
    "        markdown_content += f\"### GPT(正方)\\n{gpt_arg}\\n\\n\"\n",
    "\n",
    "        gemini_arg = call_gemini()\n",
    "        gemini_messages.append(gemini_arg)\n",
    "        display(Markdown(f\"### Gemini(反方):\\n{gemini_arg}\\n\"))\n",
    "        markdown_content += f\"### Gemini(反方)\\n{gemini_messages[i]}\\n\\n\"\n",
    "\n",
    "        llama_arg = call_llama()\n",
    "        llama_messages.append(llama_arg)\n",
    "        display(Markdown(f\"### Llamma(观众):\\n{llama_arg}\\n\"))\n",
    "        markdown_content += f\"### Llama(观众)\\n{gemini_arg}\\n\\n\"\n",
    "    \n",
    "    markdown_content += f\"\\n---\\n*Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\"\n",
    "    \n",
    "    # Save markdown\n",
    "    md_filename = f\"{topic}.md\"\n",
    "    with open(md_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(markdown_content)\n",
    "    print(f\"✓ Markdown saved: {md_filename}\")\n",
    "\n",
    "gpt_messages = [f\"大家好，我是正方辩手GPT ({gpt_model})\"]\n",
    "gemini_messages = [f\"大家好，我是反方辩手Gemini ({gemini_model})\"]\n",
    "llama_messages = []\n",
    "display_and_save_to_pdf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
